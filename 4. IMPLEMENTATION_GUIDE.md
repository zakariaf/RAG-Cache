# RAG Cache MVP - Implementation Guide with Sample Code

## Complete Code Examples Following Sandi Metz Principles

This document provides production-ready code for all critical components.

---

## Table of Contents

1. [Project Structure](#project-structure)
2. [Core Infrastructure](#core-infrastructure)
3. [Models Layer](#models-layer)
4. [Redis Cache Layer](#redis-cache-layer)
5. [Qdrant Semantic Cache](#qdrant-semantic-cache)
6. [LLM Abstraction](#llm-abstraction)
7. [Query Processing](#query-processing)
8. [API Layer](#api-layer)
9. [Testing Examples](#testing-examples)

---

## Project Structure

```
ragcache-python/
├── app/
│   ├── __init__.py
│   ├── main.py                      # FastAPI application
│   ├── config.py                    # Configuration management
│   ├── api/
│   │   ├── __init__.py
│   │   ├── deps.py                  # Dependency injection
│   │   ├── routes/
│   │   │   ├── __init__.py
│   │   │   ├── health.py
│   │   │   └── query.py
│   │   └── middleware/
│   │       ├── __init__.py
│   │       ├── auth.py
│   │       ├── logging.py
│   │       └── metrics.py
│   ├── cache/
│   │   ├── __init__.py
│   │   ├── manager.py               # Cache orchestrator
│   │   ├── redis_cache.py           # Redis operations
│   │   ├── semantic_cache.py        # Qdrant operations
│   │   └── cache_key.py             # Key generation
│   ├── llm/
│   │   ├── __init__.py
│   │   ├── provider.py              # LLM abstraction
│   │   ├── openai_provider.py
│   │   ├── anthropic_provider.py
│   │   └── factory.py
│   ├── embeddings/
│   │   ├── __init__.py
│   │   └── generator.py
│   ├── similarity/
│   │   ├── __init__.py
│   │   └── matcher.py
│   ├── models/
│   │   ├── __init__.py
│   │   ├── query.py
│   │   ├── response.py
│   │   ├── cache_entry.py
│   │   └── llm.py
│   ├── repositories/
│   │   ├── __init__.py
│   │   ├── redis_repository.py
│   │   └── qdrant_repository.py
│   ├── services/
│   │   ├── __init__.py
│   │   ├── query_service.py
│   │   ├── cache_service.py
│   │   └── metrics_service.py
│   └── utils/
│       ├── __init__.py
│       ├── logger.py
│       ├── hasher.py
│       └── validators.py
└── tests/
    └── ...
```

---

## 1. Core Infrastructure

### app/main.py - FastAPI Application

```python
"""
Main FastAPI application.

Following Sandi Metz:
- Single Responsibility: Application setup and configuration
- Small methods: Each lifecycle stage isolated
- Clear naming: Descriptive function names
"""

from contextlib import asynccontextmanager
from typing import AsyncGenerator

from fastapi import FastAPI
from fastapi.middleware.cors import CORSMiddleware
from prometheus_client import make_asgi_app

from app.api.middleware.logging import LoggingMiddleware
from app.api.middleware.metrics import MetricsMiddleware
from app.api.routes import health, query
from app.config import config
from app.utils.logger import get_logger, setup_logging

setup_logging()
logger = get_logger(__name__)


class ApplicationState:
    """
    Manages application-wide state.
    
    Single Responsibility: Lifecycle management of shared resources.
    """
    
    def __init__(self):
        self.redis_pool = None
        self.qdrant_client = None
        self.embedding_model = None
    
    async def startup(self) -> None:
        """Initialize application resources."""
        logger.info("Starting RAGCache", env=config.app_env)
        await self._initialize_redis()
        await self._initialize_qdrant()
        await self._initialize_embeddings()
    
    async def shutdown(self) -> None:
        """Cleanup application resources."""
        logger.info("Shutting down RAGCache")
        await self._cleanup_redis()
        await self._cleanup_qdrant()
        await self._cleanup_embeddings()
    
    async def _initialize_redis(self) -> None:
        """Initialize Redis connection pool."""
        from app.repositories.redis_repository import create_redis_pool
        self.redis_pool = await create_redis_pool()
        logger.info("Redis pool initialized")
    
    async def _initialize_qdrant(self) -> None:
        """Initialize Qdrant client."""
        from app.repositories.qdrant_repository import create_qdrant_client
        self.qdrant_client = await create_qdrant_client()
        logger.info("Qdrant client initialized")
    
    async def _initialize_embeddings(self) -> None:
        """Initialize embedding model."""
        from app.embeddings.generator import create_embedding_model
        self.embedding_model = create_embedding_model()
        logger.info("Embedding model loaded")
    
    async def _cleanup_redis(self) -> None:
        """Close Redis connections."""
        if self.redis_pool:
            await self.redis_pool.close()
    
    async def _cleanup_qdrant(self) -> None:
        """Close Qdrant client."""
        if self.qdrant_client:
            await self.qdrant_client.close()
    
    async def _cleanup_embeddings(self) -> None:
        """Cleanup embedding model."""
        self.embedding_model = None


@asynccontextmanager
async def lifespan(app: FastAPI) -> AsyncGenerator[None, None]:
    """Application lifespan handler."""
    state = ApplicationState()
    await state.startup()
    app.state.app_state = state
    
    yield
    
    await state.shutdown()


def create_application() -> FastAPI:
    """
    Create and configure FastAPI application.
    
    Returns:
        Configured FastAPI application instance.
    """
    app = FastAPI(
        title=config.app_name,
        description="Token-efficient RAG caching platform",
        version="0.1.0",
        docs_url="/docs" if config.is_development else None,
        redoc_url="/redoc" if config.is_development else None,
        lifespan=lifespan,
    )
    
    # Add middleware
    app.add_middleware(
        CORSMiddleware,
        allow_origins=config.allowed_origins_list,
        allow_credentials=True,
        allow_methods=["*"],
        allow_headers=["*"],
    )
    app.add_middleware(MetricsMiddleware)
    app.add_middleware(LoggingMiddleware)
    
    # Include routers
    app.include_router(health.router, tags=["health"])
    app.include_router(
        query.router,
        prefix="/api/v1",
        tags=["query"]
    )
    
    # Mount Prometheus metrics
    if config.enable_metrics:
        metrics_app = make_asgi_app()
        app.mount("/metrics", metrics_app)
    
    return app


app = create_application()


if __name__ == "__main__":
    import uvicorn
    
    uvicorn.run(
        "app.main:app",
        host=config.api_host,
        port=config.api_port,
        reload=config.is_development,
        workers=config.api_workers if not config.is_development else 1,
    )
```

---

## 2. Models Layer

### app/models/query.py - Request Models

```python
"""
Query request and validation models.

Sandi Metz Principles:
- Small classes focused on data validation
- Clear property names
- Single responsibility per model
"""

from typing import Literal, Optional

from pydantic import BaseModel, Field, field_validator


class QueryRequest(BaseModel):
    """Incoming query request with validation."""
    
    query: str = Field(
        ...,
        min_length=1,
        max_length=10000,
        description="User query text",
        examples=["What is the capital of France?"]
    )
    
    provider: Optional[Literal["openai", "anthropic"]] = Field(
        None,
        description="LLM provider to use (defaults to config)"
    )
    
    model: Optional[str] = Field(
        None,
        description="Specific model name",
        examples=["gpt-3.5-turbo", "claude-3-sonnet-20240229"]
    )
    
    max_tokens: Optional[int] = Field(
        None,
        ge=1,
        le=4000,
        description="Maximum tokens in response"
    )
    
    temperature: Optional[float] = Field(
        None,
        ge=0.0,
        le=2.0,
        description="Temperature for generation"
    )
    
    use_cache: bool = Field(
        True,
        description="Whether to use caching"
    )
    
    @field_validator("query")
    @classmethod
    def validate_query_not_empty(cls, v: str) -> str:
        """Ensure query has content after stripping whitespace."""
        stripped = v.strip()
        if not stripped:
            raise ValueError("Query cannot be empty or only whitespace")
        return stripped
    
    def get_provider(self, default: str) -> str:
        """Get provider with fallback to default."""
        return self.provider or default
    
    def get_model(self, default: str) -> str:
        """Get model with fallback to default."""
        return self.model or default
    
    def get_max_tokens(self, default: int) -> int:
        """Get max_tokens with fallback to default."""
        return self.max_tokens or default
    
    def get_temperature(self, default: float) -> float:
        """Get temperature with fallback to default."""
        return self.temperature or default
```

### app/models/response.py - Response Models

```python
"""Response models for API endpoints."""

from typing import Literal, Optional

from pydantic import BaseModel, Field


class UsageMetrics(BaseModel):
    """Token usage information."""
    
    prompt_tokens: int = Field(..., description="Tokens in prompt", ge=0)
    completion_tokens: int = Field(..., description="Tokens in completion", ge=0)
    total_tokens: int = Field(..., description="Total tokens", ge=0)
    
    @classmethod
    def create(cls, prompt: int, completion: int) -> "UsageMetrics":
        """Factory method for creating usage metrics."""
        return cls(
            prompt_tokens=prompt,
            completion_tokens=completion,
            total_tokens=prompt + completion
        )


class CacheInfo(BaseModel):
    """Cache hit information."""
    
    cache_hit: bool = Field(..., description="Whether cache was hit")
    cache_type: Optional[Literal["exact", "semantic"]] = Field(
        None,
        description="Type of cache match"
    )
    similarity_score: Optional[float] = Field(
        None,
        ge=0.0,
        le=1.0,
        description="Similarity score for semantic match"
    )
    
    @classmethod
    def miss(cls) -> "CacheInfo":
        """Factory for cache miss."""
        return cls(cache_hit=False)
    
    @classmethod
    def exact_hit(cls) -> "CacheInfo":
        """Factory for exact cache hit."""
        return cls(cache_hit=True, cache_type="exact")
    
    @classmethod
    def semantic_hit(cls, score: float) -> "CacheInfo":
        """Factory for semantic cache hit."""
        return cls(
            cache_hit=True,
            cache_type="semantic",
            similarity_score=score
        )


class QueryResponse(BaseModel):
    """Complete query response."""
    
    response: str = Field(..., description="Generated response text")
    provider: str = Field(..., description="LLM provider used")
    model: str = Field(..., description="Model used")
    usage: UsageMetrics = Field(..., description="Token usage")
    cache_info: CacheInfo = Field(..., description="Cache information")
    latency_ms: float = Field(..., description="Response latency", ge=0)
    
    def was_cached(self) -> bool:
        """Check if response came from cache."""
        return self.cache_info.cache_hit
    
    def calculate_cost_savings(self, cost_per_token: float) -> float:
        """Calculate cost saved if cached."""
        if not self.was_cached():
            return 0.0
        return self.usage.total_tokens * cost_per_token
```

### app/models/cache_entry.py - Cache Entry

```python
"""Cache entry model for storing query-response pairs."""

from datetime import datetime
from typing import Optional

from pydantic import BaseModel, Field


class CacheEntry(BaseModel):
    """
    Cached query-response pair.
    
    Single Responsibility: Data structure for cached items.
    """
    
    query_hash: str = Field(..., description="Hash of normalized query")
    original_query: str = Field(..., description="Original query text")
    response: str = Field(..., description="Cached response")
    provider: str = Field(..., description="Provider used")
    model: str = Field(..., description="Model used")
    prompt_tokens: int = Field(..., description="Tokens in prompt", ge=0)
    completion_tokens: int = Field(..., description="Tokens in response", ge=0)
    embedding: Optional[list[float]] = Field(
        None,
        description="Query embedding vector"
    )
    created_at: datetime = Field(
        default_factory=datetime.utcnow,
        description="Creation timestamp"
    )
    accessed_at: datetime = Field(
        default_factory=datetime.utcnow,
        description="Last access timestamp"
    )
    access_count: int = Field(default=1, description="Access count", ge=1)
    ttl_seconds: Optional[int] = Field(
        None,
        description="Time to live in seconds"
    )
    
    def to_redis_dict(self) -> dict[str, str]:
        """
        Convert to Redis hash format.
        
        All values must be strings for Redis hset.
        """
        return {
            "query_hash": self.query_hash,
            "original_query": self.original_query,
            "response": self.response,
            "provider": self.provider,
            "model": self.model,
            "prompt_tokens": str(self.prompt_tokens),
            "completion_tokens": str(self.completion_tokens),
            "created_at": self.created_at.isoformat(),
            "accessed_at": self.accessed_at.isoformat(),
            "access_count": str(self.access_count),
        }
    
    @classmethod
    def from_redis_dict(cls, data: dict[str, bytes]) -> "CacheEntry":
        """
        Create from Redis hash.
        
        Args:
            data: Redis hash data (bytes values)
        
        Returns:
            CacheEntry instance
        """
        return cls(
            query_hash=data[b"query_hash"].decode(),
            original_query=data[b"original_query"].decode(),
            response=data[b"response"].decode(),
            provider=data[b"provider"].decode(),
            model=data[b"model"].decode(),
            prompt_tokens=int(data[b"prompt_tokens"]),
            completion_tokens=int(data[b"completion_tokens"]),
            created_at=datetime.fromisoformat(data[b"created_at"].decode()),
            accessed_at=datetime.fromisoformat(data[b"accessed_at"].decode()),
            access_count=int(data[b"access_count"]),
        )
    
    def increment_access(self) -> None:
        """Update access tracking."""
        self.access_count += 1
        self.accessed_at = datetime.utcnow()
    
    @property
    def total_tokens(self) -> int:
        """Calculate total tokens."""
        return self.prompt_tokens + self.completion_tokens
```

---

## 3. Redis Cache Layer

### app/repositories/redis_repository.py - Redis Client

```python
"""
Redis repository for cache operations.

Sandi Metz Principles:
- Single Responsibility: Redis data access only
- Small methods: Each operation isolated
- Dependency Injection: Redis client injected
"""

from typing import Optional

import redis.asyncio as redis
from redis.asyncio import ConnectionPool

from app.config import config
from app.models.cache_entry import CacheEntry
from app.utils.logger import get_logger

logger = get_logger(__name__)


async def create_redis_pool() -> ConnectionPool:
    """
    Create Redis connection pool.
    
    Returns:
        Redis connection pool
    """
    pool = ConnectionPool.from_url(
        config.redis_url,
        max_connections=config.redis_max_connections,
        decode_responses=False,  # We handle decoding
    )
    return pool


class RedisRepository:
    """
    Redis data access layer.
    
    Handles all Redis operations for caching.
    """
    
    def __init__(self, pool: ConnectionPool):
        """
        Initialize repository.
        
        Args:
            pool: Redis connection pool
        """
        self._pool = pool
    
    async def get_client(self) -> redis.Redis:
        """Get Redis client from pool."""
        return redis.Redis(connection_pool=self._pool)
    
    async def store(
        self,
        key: str,
        entry: CacheEntry
    ) -> None:
        """
        Store cache entry in Redis.
        
        Args:
            key: Cache key
            entry: Cache entry to store
        """
        client = await self.get_client()
        
        try:
            data = entry.to_redis_dict()
            
            # Store as hash for efficient field access
            await client.hset(key, mapping=data)
            
            # Set TTL if specified
            if entry.ttl_seconds:
                await client.expire(key, entry.ttl_seconds)
            
            logger.debug("Stored in Redis", key=key)
            
        except Exception as e:
            logger.error("Redis store failed", key=key, error=str(e))
            raise
        finally:
            await client.close()
    
    async def fetch(self, key: str) -> Optional[CacheEntry]:
        """
        Fetch cache entry from Redis.
        
        Args:
            key: Cache key
        
        Returns:
            Cache entry if found, None otherwise
        """
        client = await self.get_client()
        
        try:
            data = await client.hgetall(key)
            
            if not data:
                logger.debug("Redis cache miss", key=key)
                return None
            
            entry = CacheEntry.from_redis_dict(data)
            logger.debug("Redis cache hit", key=key)
            
            # Update access tracking
            entry.increment_access()
            await self._update_access(client, key, entry)
            
            return entry
            
        except Exception as e:
            logger.error("Redis fetch failed", key=key, error=str(e))
            return None
        finally:
            await client.close()
    
    async def delete(self, key: str) -> bool:
        """
        Delete cache entry.
        
        Args:
            key: Cache key
        
        Returns:
            True if deleted, False if not found
        """
        client = await self.get_client()
        
        try:
            result = await client.delete(key)
            deleted = result > 0
            
            if deleted:
                logger.debug("Deleted from Redis", key=key)
            
            return deleted
            
        except Exception as e:
            logger.error("Redis delete failed", key=key, error=str(e))
            return False
        finally:
            await client.close()
    
    async def exists(self, key: str) -> bool:
        """
        Check if key exists.
        
        Args:
            key: Cache key
        
        Returns:
            True if exists
        """
        client = await self.get_client()
        
        try:
            return await client.exists(key) > 0
        finally:
            await client.close()
    
    async def _update_access(
        self,
        client: redis.Redis,
        key: str,
        entry: CacheEntry
    ) -> None:
        """Update access tracking fields."""
        await client.hset(
            key,
            mapping={
                "access_count": str(entry.access_count),
                "accessed_at": entry.accessed_at.isoformat(),
            }
        )
    
    async def health_check(self) -> bool:
        """
        Check Redis health.
        
        Returns:
            True if healthy
        """
        client = await self.get_client()
        
        try:
            await client.ping()
            return True
        except Exception as e:
            logger.error("Redis health check failed", error=str(e))
            return False
        finally:
            await client.close()
```

### app/cache/redis_cache.py - Redis Cache Service

```python
"""
Redis cache service layer.

Sandi Metz:
- Single Responsibility: Cache operations logic
- Dependency Injection: Repository injected
- Small methods: Each operation focused
"""

from typing import Optional

from app.models.cache_entry import CacheEntry
from app.repositories.redis_repository import RedisRepository
from app.utils.hasher import generate_cache_key
from app.utils.logger import get_logger

logger = get_logger(__name__)


class RedisCache:
    """
    Redis cache operations service.
    
    Handles exact match caching using Redis.
    """
    
    def __init__(self, repository: RedisRepository):
        """
        Initialize cache service.
        
        Args:
            repository: Redis repository instance
        """
        self._repo = repository
    
    async def get(self, query: str) -> Optional[CacheEntry]:
        """
        Get cached entry for exact query match.
        
        Args:
            query: Query text
        
        Returns:
            Cache entry if found
        """
        key = self._generate_key(query)
        return await self._repo.fetch(key)
    
    async def set(self, entry: CacheEntry) -> None:
        """
        Store entry in cache.
        
        Args:
            entry: Cache entry to store
        """
        key = self._generate_key(entry.original_query)
        await self._repo.store(key, entry)
    
    async def delete(self, query: str) -> bool:
        """
        Delete cached entry.
        
        Args:
            query: Query text
        
        Returns:
            True if deleted
        """
        key = self._generate_key(query)
        return await self._repo.delete(key)
    
    async def exists(self, query: str) -> bool:
        """
        Check if query is cached.
        
        Args:
            query: Query text
        
        Returns:
            True if cached
        """
        key = self._generate_key(query)
        return await self._repo.exists(key)
    
    def _generate_key(self, query: str) -> str:
        """
        Generate cache key for query.
        
        Args:
            query: Query text
        
        Returns:
            Cache key
        """
        return generate_cache_key(query)
```

---

## 4. Qdrant Semantic Cache

### app/repositories/qdrant_repository.py

```python
"""
Qdrant repository for semantic search.

Sandi Metz:
- Single Responsibility: Qdrant data access
- Small methods: Each operation isolated
- Clear naming: Descriptive method names
"""

from typing import Optional

from qdrant_client import AsyncQdrantClient
from qdrant_client.models import Distance, PointStruct, VectorParams

from app.config import config
from app.models.cache_entry import CacheEntry
from app.utils.logger import get_logger

logger = get_logger(__name__)


async def create_qdrant_client() -> AsyncQdrantClient:
    """
    Create Qdrant client.
    
    Returns:
        Qdrant client instance
    """
    client = AsyncQdrantClient(
        host=config.qdrant_host,
        port=config.qdrant_port,
    )
    
    # Ensure collection exists
    await _ensure_collection(client)
    
    return client


async def _ensure_collection(client: AsyncQdrantClient) -> None:
    """Create collection if it doesn't exist."""
    collections = await client.get_collections()
    collection_names = [c.name for c in collections.collections]
    
    if config.qdrant_collection_name not in collection_names:
        await client.create_collection(
            collection_name=config.qdrant_collection_name,
            vectors_config=VectorParams(
                size=config.qdrant_vector_size,
                distance=Distance.COSINE,
            ),
        )
        logger.info("Created Qdrant collection", name=config.qdrant_collection_name)


class QdrantRepository:
    """
    Qdrant data access layer.
    
    Handles vector storage and similarity search.
    """
    
    def __init__(self, client: AsyncQdrantClient):
        """
        Initialize repository.
        
        Args:
            client: Qdrant client instance
        """
        self._client = client
        self._collection = config.qdrant_collection_name
    
    async def store(
        self,
        entry: CacheEntry,
        embedding: list[float]
    ) -> None:
        """
        Store entry with embedding.
        
        Args:
            entry: Cache entry
            embedding: Query embedding vector
        """
        try:
            point = PointStruct(
                id=entry.query_hash,
                vector=embedding,
                payload={
                    "original_query": entry.original_query,
                    "response": entry.response,
                    "provider": entry.provider,
                    "model": entry.model,
                    "prompt_tokens": entry.prompt_tokens,
                    "completion_tokens": entry.completion_tokens,
                    "created_at": entry.created_at.isoformat(),
                },
            )
            
            await self._client.upsert(
                collection_name=self._collection,
                points=[point],
            )
            
            logger.debug("Stored in Qdrant", id=entry.query_hash)
            
        except Exception as e:
            logger.error("Qdrant store failed", error=str(e))
            raise
    
    async def search(
        self,
        embedding: list[float],
        threshold: float,
        limit: int = 1
    ) -> Optional[tuple[CacheEntry, float]]:
        """
        Search for similar embeddings.
        
        Args:
            embedding: Query embedding vector
            threshold: Minimum similarity score
            limit: Maximum results to return
        
        Returns:
            Tuple of (cache entry, similarity score) if found
        """
        try:
            results = await self._client.search(
                collection_name=self._collection,
                query_vector=embedding,
                limit=limit,
                score_threshold=threshold,
            )
            
            if not results:
                logger.debug("Qdrant: no matches above threshold")
                return None
            
            best_match = results[0]
            score = best_match.score
            
            # Convert payload to CacheEntry
            entry = self._payload_to_entry(
                best_match.payload,
                best_match.id
            )
            
            logger.debug(
                "Qdrant match found",
                score=score,
                query=entry.original_query
            )
            
            return (entry, score)
            
        except Exception as e:
            logger.error("Qdrant search failed", error=str(e))
            return None
    
    def _payload_to_entry(
        self,
        payload: dict,
        query_hash: str
    ) -> CacheEntry:
        """Convert Qdrant payload to CacheEntry."""
        from datetime import datetime
        
        return CacheEntry(
            query_hash=query_hash,
            original_query=payload["original_query"],
            response=payload["response"],
            provider=payload["provider"],
            model=payload["model"],
            prompt_tokens=payload["prompt_tokens"],
            completion_tokens=payload["completion_tokens"],
            created_at=datetime.fromisoformat(payload["created_at"]),
        )
    
    async def health_check(self) -> bool:
        """
        Check Qdrant health.
        
        Returns:
            True if healthy
        """
        try:
            await self._client.get_collections()
            return True
        except Exception as e:
            logger.error("Qdrant health check failed", error=str(e))
            return False
```

[Continue in next response due to length...]
